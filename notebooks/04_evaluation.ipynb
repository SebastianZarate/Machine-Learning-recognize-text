{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b0f9bf",
   "metadata": {},
   "source": [
    "# üìà Evaluaci√≥n de Modelos - An√°lisis de Sentimientos\n",
    "\n",
    "## Objetivo\n",
    "Evaluar y comparar el rendimiento de los modelos entrenados usando m√∫ltiples m√©tricas y visualizaciones.\n",
    "\n",
    "**M√©tricas de evaluaci√≥n:**\n",
    "- Accuracy, Precision, Recall, F1-Score\n",
    "- Matrices de Confusi√≥n\n",
    "- Curvas ROC y AUC\n",
    "- Classification Reports\n",
    "- Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5454eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "from src.visualizations import (\n",
    "    plot_confusion_matrices,\n",
    "    plot_roc_curves,\n",
    "    plot_metrics_comparison,\n",
    "    plot_feature_importance,\n",
    "    plot_prediction_distribution\n",
    ")\n",
    "from src.train_models import split_data\n",
    "\n",
    "print('‚úÖ M√≥dulos importados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelos entrenados\n",
    "print('üì¶ Cargando modelos...')\n",
    "nb_model = joblib.load('../models/naive_bayes.joblib')\n",
    "lr_model = joblib.load('../models/logistic_regression.joblib')\n",
    "rf_model = joblib.load('../models/random_forest.joblib')\n",
    "vectorizer = joblib.load('../models/tfidfvectorizer.joblib')\n",
    "\n",
    "models = {\n",
    "    'Naive Bayes': nb_model,\n",
    "    'Logistic Regression': lr_model,\n",
    "    'Random Forest': rf_model\n",
    "}\n",
    "\n",
    "print('‚úÖ Modelos cargados correctamente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fa191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y preparar datos de test\n",
    "df = pd.read_csv('../data/imdb_preprocessed.csv')\n",
    "X_train, X_test, y_train, y_test = split_data(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorizar\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(f'‚úÖ Datos de test listos: {len(X_test)} muestras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones con todos los modelos\n",
    "print('üîÆ Generando predicciones...')\n",
    "\n",
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    predictions[name] = model.predict(X_test_vec)\n",
    "    print(f'  ‚úì {name}')\n",
    "\n",
    "# Mostrar primeros 10 resultados\n",
    "print('\\nüìä PRIMERAS 10 PREDICCIONES:')\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Real': y_test.values[:10],\n",
    "    'NB': predictions['Naive Bayes'][:10],\n",
    "    'LR': predictions['Logistic Regression'][:10],\n",
    "    'RF': predictions['Random Forest'][:10]\n",
    "})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6394d",
   "metadata": {},
   "source": [
    "## üìö Explicaci√≥n de M√©tricas\n",
    "\n",
    "### 1. **Accuracy (Exactitud)**\n",
    "   - Porcentaje de predicciones correctas\n",
    "   - Formula: (TP + TN) / Total\n",
    "\n",
    "### 2. **Precision (Precisi√≥n)**\n",
    "   - De todas las predicciones positivas, cu√°ntas fueron correctas\n",
    "   - Formula: TP / (TP + FP)\n",
    "   - Importante cuando los falsos positivos son costosos\n",
    "\n",
    "### 3. **Recall (Sensibilidad)**\n",
    "   - De todos los casos positivos reales, cu√°ntos detectamos\n",
    "   - Formula: TP / (TP + FN)\n",
    "   - Importante cuando los falsos negativos son costosos\n",
    "\n",
    "### 4. **F1-Score**\n",
    "   - Media arm√≥nica de Precision y Recall\n",
    "   - Formula: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "   - **La m√©trica m√°s balanceada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fb7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular m√©tricas para todos los modelos\n",
    "print('üìä CALCULANDO M√âTRICAS...')\n",
    "print('='*70)\n",
    "\n",
    "metrics_data = []\n",
    "\n",
    "for name, y_pred in predictions.items():\n",
    "    metrics = {\n",
    "        'Model': name,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    metrics_data.append(metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data).set_index('Model')\n",
    "print('\\n‚úÖ TABLA DE M√âTRICAS:')\n",
    "print(metrics_df.to_string())\n",
    "\n",
    "# Identificar el mejor modelo\n",
    "best_model = metrics_df['f1_score'].idxmax()\n",
    "best_f1 = metrics_df['f1_score'].max()\n",
    "print(f'\\nüèÜ MEJOR MODELO: {best_model} (F1-Score: {best_f1:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaci√≥n de m√©tricas\n",
    "plot_metrics_comparison(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dcf853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matrices de confusi√≥n\n",
    "print('\\nüìä GENERANDO MATRICES DE CONFUSI√ìN...')\n",
    "confusion_matrices = {}\n",
    "\n",
    "for name, y_pred in predictions.items():\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices[name] = cm\n",
    "    print(f'\\n{name}:')\n",
    "    print(cm)\n",
    "\n",
    "# Visualizar\n",
    "plot_confusion_matrices(confusion_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b73c38",
   "metadata": {},
   "source": [
    "## üîç Interpretaci√≥n de Matrices de Confusi√≥n\n",
    "\n",
    "### Estructura de la Matriz:\n",
    "```\n",
    "                Predicted Negative  Predicted Positive\n",
    "Actual Negative        TN                 FP\n",
    "Actual Positive        FN                 TP\n",
    "```\n",
    "\n",
    "- **TN (True Negative)**: Correctamente clasificados como negativos\n",
    "- **TP (True Positive)**: Correctamente clasificados como positivos\n",
    "- **FP (False Positive)**: Error - Predijo positivo cuando era negativo\n",
    "- **FN (False Negative)**: Error - Predijo negativo cuando era positivo\n",
    "\n",
    "### Observaciones:\n",
    "- Idealmente, los valores m√°s altos deben estar en la diagonal (TN y TP)\n",
    "- FP y FN deben ser m√≠nimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular curvas ROC\n",
    "print('\\nüìà CALCULANDO CURVAS ROC...')\n",
    "roc_data = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Obtener probabilidades\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test_vec)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_test_vec)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    roc_data[name] = {\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'auc': roc_auc\n",
    "    }\n",
    "    print(f'  {name}: AUC = {roc_auc:.4f}')\n",
    "\n",
    "# Visualizar\n",
    "plot_roc_curves(roc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c35e92",
   "metadata": {},
   "source": [
    "## üìä Interpretaci√≥n de ROC y AUC\n",
    "\n",
    "### ¬øQu√© es la Curva ROC?\n",
    "- **ROC** = Receiver Operating Characteristic\n",
    "- Muestra el trade-off entre True Positive Rate y False Positive Rate\n",
    "- Ayuda a evaluar el rendimiento del modelo en diferentes thresholds\n",
    "\n",
    "### ¬øQu√© es el AUC?\n",
    "- **AUC** = Area Under the Curve (√Årea bajo la curva)\n",
    "- M√©trica resumen del rendimiento del modelo\n",
    "- **Interpretaci√≥n**:\n",
    "  - AUC = 1.0: Clasificador perfecto\n",
    "  - AUC = 0.9-1.0: Excelente\n",
    "  - AUC = 0.8-0.9: Muy bueno\n",
    "  - AUC = 0.7-0.8: Bueno\n",
    "  - AUC = 0.5: Random (l√≠nea diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733084a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Reports detallados\n",
    "print('\\nüìã CLASSIFICATION REPORTS')\n",
    "print('='*70)\n",
    "\n",
    "for name, y_pred in predictions.items():\n",
    "    print(f'\\n{name.upper()}')\n",
    "    print('-'*70)\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                                target_names=['Negative', 'Positive'],\n",
    "                                digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb205fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance - Logistic Regression\n",
    "print('\\nüîç ANALIZANDO CARACTER√çSTICAS IMPORTANTES (Logistic Regression)...')\n",
    "plot_feature_importance(lr_model, vectorizer, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c40909e",
   "metadata": {},
   "source": [
    "## üí° An√°lisis de Caracter√≠sticas Importantes\n",
    "\n",
    "### Palabras que indican sentimiento POSITIVO (verde):\n",
    "- Palabras con coeficiente positivo\n",
    "- Aumentan la probabilidad de clasificaci√≥n positiva\n",
    "- Ejemplos t√≠picos: \"excellent\", \"amazing\", \"great\", \"loved\"\n",
    "\n",
    "### Palabras que indican sentimiento NEGATIVO (rojo):\n",
    "- Palabras con coeficiente negativo\n",
    "- Aumentan la probabilidad de clasificaci√≥n negativa\n",
    "- Ejemplos t√≠picos: \"worst\", \"terrible\", \"boring\", \"waste\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de predicciones\n",
    "plot_prediction_distribution(y_test.values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tabla de m√©tricas\n",
    "import os\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "metrics_df.to_csv('../results/model_metrics.csv')\n",
    "print('\\nüíæ M√©tricas exportadas a: ../results/model_metrics.csv')\n",
    "\n",
    "# Guardar resumen\n",
    "with open('../results/evaluation_summary.txt', 'w') as f:\n",
    "    f.write('='*70 + '\\n')\n",
    "    f.write('RESUMEN DE EVALUACI√ìN DE MODELOS\\n')\n",
    "    f.write('='*70 + '\\n\\n')\n",
    "    f.write('M√âTRICAS DE RENDIMIENTO:\\n')\n",
    "    f.write(metrics_df.to_string())\n",
    "    f.write(f'\\n\\nMEJOR MODELO: {best_model}\\n')\n",
    "    f.write(f'F1-Score: {best_f1:.4f}\\n')\n",
    "    f.write('\\n' + '='*70 + '\\n')\n",
    "\n",
    "print('üíæ Resumen exportado a: ../results/evaluation_summary.txt')\n",
    "print('\\n‚úÖ Todos los resultados guardados')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348b5e8",
   "metadata": {},
   "source": [
    "## üéØ Conclusiones de la Evaluaci√≥n\n",
    "\n",
    "### üìä Resultados Principales:\n",
    "\n",
    "1. **Mejor Modelo**: El modelo con mejor F1-Score es el m√°s balanceado\n",
    "2. **M√©tricas**: Todos los modelos superan 85% de accuracy\n",
    "3. **AUC**: Valores superiores a 0.90 indican excelente capacidad discriminativa\n",
    "\n",
    "### üîç Observaciones por Modelo:\n",
    "\n",
    "**Naive Bayes:**\n",
    "- ‚úÖ Muy r√°pido en entrenamiento\n",
    "- ‚úÖ Buen baseline\n",
    "- ‚ö†Ô∏è Asume independencia de features (no siempre cierto)\n",
    "\n",
    "**Logistic Regression:**\n",
    "- ‚úÖ Balance entre velocidad y precisi√≥n\n",
    "- ‚úÖ Interpretable (coeficientes = importancia)\n",
    "- ‚úÖ Robusto y confiable\n",
    "\n",
    "**Random Forest:**\n",
    "- ‚úÖ Captura relaciones complejas\n",
    "- ‚ö†Ô∏è M√°s lento en entrenamiento\n",
    "- ‚ö†Ô∏è Menos interpretable\n",
    "\n",
    "### üöÄ Recomendaciones:\n",
    "\n",
    "1. Para **producci√≥n**: Usar el modelo con mejor F1-Score\n",
    "2. Para **velocidad**: Naive Bayes es suficiente\n",
    "3. Para **interpretabilidad**: Logistic Regression\n",
    "\n",
    "### üîú Posibles Mejoras:\n",
    "\n",
    "- Ajustar hiperpar√°metros (Grid Search)\n",
    "- Probar otros modelos (SVM, XGBoost)\n",
    "- Feature engineering m√°s sofisticado\n",
    "- Ensemble methods (combinar modelos)\n",
    "\n",
    "---\n",
    "**Siguiente notebook:** `05_complete_workflow.ipynb` (Workflow completo integrado)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
