{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea099a0",
   "metadata": {},
   "source": [
    "# üßπ Preprocesamiento de Texto - IMDB Dataset\n",
    "\n",
    "## Objetivo\n",
    "Aplicar t√©cnicas de preprocesamiento de texto para limpiar y normalizar las rese√±as antes del entrenamiento de modelos.\n",
    "\n",
    "**Pipeline de Preprocesamiento:**\n",
    "1. Limpieza de HTML, URLs, caracteres especiales\n",
    "2. Conversi√≥n a min√∫sculas\n",
    "3. Eliminaci√≥n de stopwords\n",
    "4. Lematizaci√≥n\n",
    "5. Conversi√≥n de sentimientos a valores num√©ricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.preprocessing import (\n",
    "    load_imdb_dataset,\n",
    "    clean_text_advanced,\n",
    "    remove_stopwords,\n",
    "    lemmatize_text,\n",
    "    preprocess_pipeline,\n",
    "    preprocess_dataframe\n",
    ")\n",
    "\n",
    "print('‚úÖ M√≥dulos importados correctamente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b16d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos originales\n",
    "df_raw = load_imdb_dataset('../IMDB Dataset.csv')\n",
    "print(f'\\n‚úÖ Dataset cargado: {len(df_raw)} rese√±as')\n",
    "print(f'Columnas: {list(df_raw.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ead5b5",
   "metadata": {},
   "source": [
    "## üìù Pipeline de Limpieza de Texto\n",
    "\n",
    "### Pasos del Preprocesamiento:\n",
    "\n",
    "1. **Limpieza Avanzada (`clean_text_advanced`)**:\n",
    "   - Eliminar tags HTML (`<br>`, `<p>`, etc.)\n",
    "   - Eliminar URLs y emails\n",
    "   - Eliminar menciones (@usuario)\n",
    "   - Eliminar n√∫meros\n",
    "   - Eliminar caracteres especiales\n",
    "   - Normalizar espacios\n",
    "\n",
    "2. **Eliminaci√≥n de Stopwords (`remove_stopwords`)**:\n",
    "   - Eliminar palabras comunes sin valor sem√°ntico (the, a, an, is, etc.)\n",
    "\n",
    "3. **Lematizaci√≥n (`lemmatize_text`)**:\n",
    "   - Reducir palabras a su forma base (running ‚Üí run, movies ‚Üí movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo pr√°ctico: Texto raw vs procesado\n",
    "print('üîç EJEMPLO DE PREPROCESAMIENTO PASO A PASO')\n",
    "print('='*70)\n",
    "\n",
    "# Tomar una rese√±a de ejemplo\n",
    "sample_review = df_raw['review'].iloc[0]\n",
    "\n",
    "print('\\n1Ô∏è‚É£ TEXTO ORIGINAL:')\n",
    "print('-'*70)\n",
    "print(sample_review[:500] + '...')  # Primeros 500 caracteres\n",
    "\n",
    "# Paso 1: Limpieza avanzada\n",
    "step1 = clean_text_advanced(sample_review)\n",
    "print('\\n2Ô∏è‚É£ DESPU√âS DE LIMPIEZA AVANZADA:')\n",
    "print('-'*70)\n",
    "print(step1[:500] + '...')\n",
    "\n",
    "# Paso 2: Eliminaci√≥n de stopwords\n",
    "step2 = remove_stopwords(step1)\n",
    "print('\\n3Ô∏è‚É£ DESPU√âS DE ELIMINAR STOPWORDS:')\n",
    "print('-'*70)\n",
    "print(step2[:500] + '...')\n",
    "\n",
    "# Paso 3: Lematizaci√≥n\n",
    "step3 = lemmatize_text(step2)\n",
    "print('\\n4Ô∏è‚É£ DESPU√âS DE LEMATIZACI√ìN (TEXTO FINAL):')\n",
    "print('-'*70)\n",
    "print(step3[:500] + '...')\n",
    "\n",
    "# Mostrar reducci√≥n\n",
    "print('\\nüìä COMPARACI√ìN DE LONGITUDES:')\n",
    "print(f'Original: {len(sample_review)} caracteres')\n",
    "print(f'Final: {len(step3)} caracteres')\n",
    "print(f'Reducci√≥n: {((len(sample_review) - len(step3)) / len(sample_review) * 100):.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar preprocesamiento a todo el dataset\n",
    "print('\\nüöÄ APLICANDO PREPROCESAMIENTO A TODO EL DATASET')\n",
    "print('='*70)\n",
    "print('‚è≥ Este proceso puede tomar varios minutos...')\n",
    "\n",
    "start_time = time.time()\n",
    "df_processed = preprocess_dataframe(df_raw)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f'\\n‚è±Ô∏è Tiempo total: {elapsed_time:.2f} segundos ({elapsed_time/60:.2f} minutos)')\n",
    "print(f'‚ö° Velocidad: {len(df_processed)/elapsed_time:.1f} rese√±as/segundo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dfbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar antes y despu√©s\n",
    "print('\\nüìä COMPARACI√ìN ANTES Y DESPU√âS DEL PREPROCESAMIENTO')\n",
    "print('='*70)\n",
    "\n",
    "print('\\nüîµ DATASET ORIGINAL:')\n",
    "print(df_raw.head())\n",
    "print(f'\\nColumnas: {list(df_raw.columns)}')\n",
    "print(f'Tipo de sentiment: {df_raw[\"sentiment\"].dtype}')\n",
    "\n",
    "print('\\nüü¢ DATASET PROCESADO:')\n",
    "print(df_processed.head())\n",
    "print(f'\\nColumnas: {list(df_processed.columns)}')\n",
    "print(f'Tipo de sentiment: {df_processed[\"sentiment\"].dtype}')\n",
    "\n",
    "print('\\n‚ú® CAMBIOS APLICADOS:')\n",
    "print(f'  ‚Ä¢ Nueva columna \"review_clean\" con texto preprocesado')\n",
    "print(f'  ‚Ä¢ Columna \"sentiment\" convertida a num√©rica (0=negativo, 1=positivo)')\n",
    "print(f'  ‚Ä¢ Rese√±as vac√≠as eliminadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60df7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar resultados con ejemplos aleatorios\n",
    "print('\\nüé≤ EJEMPLOS ALEATORIOS DE TEXTOS PROCESADOS')\n",
    "print('='*70)\n",
    "\n",
    "sample_indices = np.random.choice(df_processed.index, 5, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    print(f'\\n--- EJEMPLO {i} ---')\n",
    "    print(f'Sentimiento: {\"POSITIVO\" if df_processed.loc[idx, \"sentiment\"] == 1 else \"NEGATIVO\"}')\n",
    "    print(f'Original: {df_processed.loc[idx, \"review\"][:150]}...')\n",
    "    print(f'Procesado: {df_processed.loc[idx, \"review_clean\"][:150]}...')\n",
    "\n",
    "# Verificar valores nulos\n",
    "print('\\n\\n‚úÖ VERIFICACI√ìN DE CALIDAD DE DATOS:')\n",
    "print(f'Valores nulos en review_clean: {df_processed[\"review_clean\"].isnull().sum()}')\n",
    "print(f'Valores nulos en sentiment: {df_processed[\"sentiment\"].isnull().sum()}')\n",
    "print(f'Textos vac√≠os: {(df_processed[\"review_clean\"].str.len() == 0).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar dataset procesado\n",
    "import os\n",
    "\n",
    "output_path = '../data/imdb_preprocessed.csv'\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "df_processed.to_csv(output_path, index=False)\n",
    "\n",
    "print('\\nüíæ DATASET PROCESADO GUARDADO')\n",
    "print('='*70)\n",
    "print(f'Ruta: {output_path}')\n",
    "print(f'Tama√±o del archivo: {os.path.getsize(output_path) / (1024*1024):.2f} MB')\n",
    "print(f'Filas guardadas: {len(df_processed)}')\n",
    "print(f'Columnas: {list(df_processed.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711e5139",
   "metadata": {},
   "source": [
    "## üéØ Conclusiones del Preprocesamiento\n",
    "\n",
    "### ‚úÖ Tareas Completadas:\n",
    "\n",
    "1. **Limpieza Exitosa**: Se eliminaron tags HTML, URLs, caracteres especiales y elementos no deseados del texto.\n",
    "\n",
    "2. **Normalizaci√≥n**: Todo el texto fue convertido a min√∫sculas y se normalizaron los espacios.\n",
    "\n",
    "3. **Reducci√≥n de Ruido**: Se eliminaron stopwords que no aportan significado sem√°ntico.\n",
    "\n",
    "4. **Lematizaci√≥n**: Las palabras fueron reducidas a su forma base para mejorar la generalizaci√≥n.\n",
    "\n",
    "5. **Conversi√≥n Num√©rica**: Los sentimientos fueron convertidos a formato num√©rico (0/1) para el entrenamiento.\n",
    "\n",
    "### üìà Impacto del Preprocesamiento:\n",
    "\n",
    "- **Reducci√≥n de dimensionalidad**: Los textos son m√°s cortos y concisos\n",
    "- **Mejor generalizaci√≥n**: La lematizaci√≥n ayuda a que palabras similares se traten como una sola\n",
    "- **Menos ruido**: Se elimin√≥ informaci√≥n irrelevante que podr√≠a confundir a los modelos\n",
    "- **Datos listos**: El dataset est√° ahora listo para vectorizaci√≥n y entrenamiento\n",
    "\n",
    "### üîú Pr√≥ximos Pasos:\n",
    "\n",
    "1. Dividir datos en train/test\n",
    "2. Vectorizar textos (Bag of Words o TF-IDF)\n",
    "3. Entrenar modelos de Machine Learning\n",
    "\n",
    "---\n",
    "**Siguiente notebook:** `03_model_training.ipynb`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
