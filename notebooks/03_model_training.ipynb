{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d39c637",
   "metadata": {},
   "source": [
    "# ü§ñ Entrenamiento de Modelos - An√°lisis de Sentimientos\n",
    "\n",
    "## Objetivo\n",
    "Entrenar m√∫ltiples modelos de Machine Learning para clasificar sentimientos en rese√±as de pel√≠culas.\n",
    "\n",
    "**Modelos a entrenar:**\n",
    "1. Naive Bayes (MultinomialNB)\n",
    "2. Regresi√≥n Log√≠stica\n",
    "3. Random Forest\n",
    "\n",
    "**Vectorizaci√≥n:**\n",
    "- CountVectorizer (Bag of Words)\n",
    "- TfidfVectorizer (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f18b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.train_models import (\n",
    "    split_data,\n",
    "    create_vectorizers,\n",
    "    vectorize_data,\n",
    "    train_naive_bayes,\n",
    "    train_logistic_regression,\n",
    "    train_random_forest,\n",
    "    train_all_models,\n",
    "    save_models\n",
    ")\n",
    "\n",
    "print('‚úÖ M√≥dulos importados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos procesados\n",
    "df = pd.read_csv('../data/imdb_preprocessed.csv')\n",
    "print(f'‚úÖ Dataset cargado: {len(df)} rese√±as')\n",
    "print(f'Columnas: {list(df.columns)}')\n",
    "print(f'\\nPrimeras filas:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767456a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en Train/Test\n",
    "X_train, X_test, y_train, y_test = split_data(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print('\\n‚úÖ Datos divididos correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d52c03",
   "metadata": {},
   "source": [
    "## üìä Vectorizaci√≥n de Texto\n",
    "\n",
    "### ¬øQu√© es la vectorizaci√≥n?\n",
    "Los modelos de ML no pueden trabajar directamente con texto. Necesitamos convertir las palabras en n√∫meros.\n",
    "\n",
    "### T√©cnicas de Vectorizaci√≥n:\n",
    "\n",
    "**1. Bag of Words (CountVectorizer)**\n",
    "- Cuenta la frecuencia de cada palabra\n",
    "- Simple pero efectivo\n",
    "- No considera la importancia relativa de las palabras\n",
    "\n",
    "**2. TF-IDF (TfidfVectorizer)**\n",
    "- Term Frequency - Inverse Document Frequency\n",
    "- Penaliza palabras muy comunes\n",
    "- Da m√°s peso a palabras distintivas\n",
    "- **Generalmente mejor para clasificaci√≥n de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear vectorizadores\n",
    "count_vec, tfidf_vec = create_vectorizers()\n",
    "\n",
    "print('\\nüìù Probando ambos vectorizadores...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b11a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar CountVectorizer\n",
    "print('\\n1Ô∏è‚É£ PROBANDO COUNT VECTORIZER (BAG OF WORDS)')\n",
    "X_train_count, X_test_count, count_vec_fitted = vectorize_data(X_train, X_test, count_vec)\n",
    "\n",
    "print(f'\\nShape entrenamiento: {X_train_count.shape}')\n",
    "print(f'Shape prueba: {X_test_count.shape}')\n",
    "print(f'Tipo de datos: {type(X_train_count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd780b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar TfidfVectorizer\n",
    "print('\\n2Ô∏è‚É£ PROBANDO TF-IDF VECTORIZER')\n",
    "X_train_tfidf, X_test_tfidf, tfidf_vec_fitted = vectorize_data(X_train, X_test, tfidf_vec)\n",
    "\n",
    "print(f'\\nShape entrenamiento: {X_train_tfidf.shape}')\n",
    "print(f'Shape prueba: {X_test_tfidf.shape}')\n",
    "print(f'Tipo de datos: {type(X_train_tfidf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04999c",
   "metadata": {},
   "source": [
    "## ‚úÖ Decisi√≥n de Vectorizador\n",
    "\n",
    "**Usaremos TF-IDF** por las siguientes razones:\n",
    "\n",
    "1. ‚úÖ Mejor manejo de palabras comunes\n",
    "2. ‚úÖ Da m√°s importancia a palabras distintivas\n",
    "3. ‚úÖ Generalmente superior en tareas de clasificaci√≥n de texto\n",
    "4. ‚úÖ Normalizaci√≥n autom√°tica de frecuencias\n",
    "\n",
    "Ambos vectorizadores generan la misma dimensionalidad (5000 features con bigramas), pero TF-IDF produce representaciones m√°s discriminativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos TF-IDF para el entrenamiento\n",
    "X_train_vec = X_train_tfidf\n",
    "X_test_vec = X_test_tfidf\n",
    "vectorizer = tfidf_vec_fitted\n",
    "\n",
    "print('‚úÖ Vectorizador seleccionado: TF-IDF')\n",
    "print(f'Features: {X_train_vec.shape[1]}')\n",
    "print(f'Muestras entrenamiento: {X_train_vec.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd99f7d1",
   "metadata": {},
   "source": [
    "## üöÄ Entrenamiento de Modelos\n",
    "\n",
    "### Modelo 1: Naive Bayes\n",
    "- **Tipo**: Clasificador probabil√≠stico\n",
    "- **Ventaja**: R√°pido, funciona bien con texto\n",
    "- **Basado en**: Teorema de Bayes\n",
    "- **Uso**: Baseline com√∫n para clasificaci√≥n de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ac5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Naive Bayes\n",
    "start_time = time.time()\n",
    "nb_model = train_naive_bayes(X_train_vec, y_train)\n",
    "nb_time = time.time() - start_time\n",
    "\n",
    "# Prueba r√°pida\n",
    "nb_score = nb_model.score(X_test_vec, y_test)\n",
    "print(f'\\nüìä Accuracy en test: {nb_score:.4f}')\n",
    "print(f'‚è±Ô∏è Tiempo de entrenamiento: {nb_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc8564",
   "metadata": {},
   "source": [
    "### Modelo 2: Regresi√≥n Log√≠stica\n",
    "- **Tipo**: Clasificador lineal\n",
    "- **Ventaja**: Interpretable, robusto\n",
    "- **Regularizaci√≥n**: L2 (Ridge)\n",
    "- **Uso**: Excelente para alta dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81100fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Regresi√≥n Log√≠stica\n",
    "start_time = time.time()\n",
    "lr_model = train_logistic_regression(X_train_vec, y_train)\n",
    "lr_time = time.time() - start_time\n",
    "\n",
    "# Prueba r√°pida\n",
    "lr_score = lr_model.score(X_test_vec, y_test)\n",
    "print(f'\\nüìä Accuracy en test: {lr_score:.4f}')\n",
    "print(f'‚è±Ô∏è Tiempo de entrenamiento: {lr_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074c5b6",
   "metadata": {},
   "source": [
    "### Modelo 3: Random Forest\n",
    "- **Tipo**: Ensemble de √°rboles de decisi√≥n\n",
    "- **Ventaja**: Captura relaciones no lineales\n",
    "- **Par√°metros**: 100 √°rboles, profundidad m√°xima 50\n",
    "- **Nota**: M√°s lento pero potencialmente m√°s preciso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Random Forest\n",
    "start_time = time.time()\n",
    "rf_model = train_random_forest(X_train_vec, y_train)\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "# Prueba r√°pida\n",
    "rf_score = rf_model.score(X_test_vec, y_test)\n",
    "print(f'\\nüìä Accuracy en test: {rf_score:.4f}')\n",
    "print(f'‚è±Ô∏è Tiempo de entrenamiento: {rf_time:.2f}s ({rf_time/60:.2f} min)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear diccionario de modelos\n",
    "models = {\n",
    "    'naive_bayes': nb_model,\n",
    "    'logistic_regression': lr_model,\n",
    "    'random_forest': rf_model\n",
    "}\n",
    "\n",
    "print('‚úÖ Todos los modelos entrenados correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f333058",
   "metadata": {},
   "source": [
    "## üìä Comparaci√≥n de Tiempos de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cdd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla comparativa de tiempos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "times_df = pd.DataFrame({\n",
    "    'Modelo': ['Naive Bayes', 'Logistic Regression', 'Random Forest'],\n",
    "    'Tiempo (segundos)': [nb_time, lr_time, rf_time],\n",
    "    'Accuracy': [nb_score, lr_score, rf_score]\n",
    "})\n",
    "\n",
    "print('\\n‚è±Ô∏è COMPARACI√ìN DE TIEMPOS Y ACCURACY')\n",
    "print('='*60)\n",
    "print(times_df.to_string(index=False))\n",
    "\n",
    "# Visualizar\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gr√°fico de tiempos\n",
    "axes[0].bar(times_df['Modelo'], times_df['Tiempo (segundos)'], \n",
    "           color=['#3498db', '#2ecc71', '#e74c3c'], alpha=0.8)\n",
    "axes[0].set_title('Tiempo de Entrenamiento', fontweight='bold')\n",
    "axes[0].set_ylabel('Segundos')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gr√°fico de accuracy\n",
    "axes[1].bar(times_df['Modelo'], times_df['Accuracy'], \n",
    "           color=['#3498db', '#2ecc71', '#e74c3c'], alpha=0.8)\n",
    "axes[1].set_title('Accuracy en Test', fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_ylim([0.7, 1.0])\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Agregar valores\n",
    "for i, v in enumerate(times_df['Tiempo (segundos)']):\n",
    "    axes[0].text(i, v, f'{v:.1f}s', ha='center', va='bottom')\n",
    "for i, v in enumerate(times_df['Accuracy']):\n",
    "    axes[1].text(i, v, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelos\n",
    "save_models(models, vectorizer, output_dir='../models/')\n",
    "\n",
    "print('\\n‚úÖ Modelos y vectorizador guardados exitosamente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a360690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar archivos guardados\n",
    "import os\n",
    "\n",
    "print('\\nüìÅ ARCHIVOS GUARDADOS EN ../models/')\n",
    "print('='*60)\n",
    "model_files = os.listdir('../models/')\n",
    "for file in model_files:\n",
    "    file_path = os.path.join('../models/', file)\n",
    "    size_mb = os.path.getsize(file_path) / (1024*1024)\n",
    "    print(f'  ‚úì {file:<30} {size_mb:>10.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db955210",
   "metadata": {},
   "source": [
    "## üéØ Resumen del Entrenamiento\n",
    "\n",
    "### ‚úÖ Tareas Completadas:\n",
    "\n",
    "1. **Divisi√≥n de Datos**: 80% entrenamiento, 20% prueba\n",
    "2. **Vectorizaci√≥n**: TF-IDF con 5000 features y bigramas\n",
    "3. **Modelos Entrenados**: 3 modelos diferentes con distintas arquitecturas\n",
    "4. **Persistencia**: Modelos y vectorizador guardados en disco\n",
    "\n",
    "### üìä Observaciones Iniciales:\n",
    "\n",
    "- **Naive Bayes**: El m√°s r√°pido, buen baseline\n",
    "- **Logistic Regression**: Balance entre velocidad y accuracy\n",
    "- **Random Forest**: M√°s lento pero con buen rendimiento\n",
    "\n",
    "### üîú Pr√≥ximos Pasos:\n",
    "\n",
    "En el siguiente notebook realizaremos una **evaluaci√≥n exhaustiva** de los modelos:\n",
    "- M√©tricas detalladas (Precision, Recall, F1-Score)\n",
    "- Matrices de confusi√≥n\n",
    "- Curvas ROC\n",
    "- An√°lisis de caracter√≠sticas importantes\n",
    "- Selecci√≥n del mejor modelo\n",
    "\n",
    "---\n",
    "**Siguiente notebook:** `04_evaluation.ipynb`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
