# ğŸ¬ AnÃ¡lisis de Sentimientos en ReseÃ±as de PelÃ­culas

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![NLTK](https://img.shields.io/badge/NLTK-3.6+-green.svg)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**Sistema completo de Machine Learning para clasificar sentimientos en reseÃ±as de pelÃ­culas utilizando 3 algoritmos supervisados**

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢ [InstalaciÃ³n](#-instalaciÃ³n) â€¢ [Uso](#-uso) â€¢ [Notebooks](#-notebooks) â€¢ [Resultados](#-resultados)

</div>

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un **pipeline completo de Machine Learning** para **clasificar sentimientos** (positivo/negativo) en reseÃ±as de pelÃ­culas del dataset IMDB. Se comparan **3 algoritmos de clasificaciÃ³n supervisada**:

- ğŸ¯ **Naive Bayes** (MultinomialNB) - Baseline rÃ¡pido y eficiente
- ğŸ“ˆ **Logistic Regression** - Balance entre velocidad y precisiÃ³n
- ğŸŒ³ **Random Forest** - Ensemble robusto para patrones complejos

### ğŸ¯ Objetivos del Proyecto

1. **Entrenar y comparar** 3 modelos de clasificaciÃ³n supervisada
2. **Evaluar** rendimiento con mÃ©tricas completas (accuracy, precision, recall, F1, ROC-AUC)
3. **Visualizar** resultados con grÃ¡ficos profesionales (confusion matrix, ROC curves, wordclouds)
4. **Documentar** proceso completo en notebooks interactivos de Jupyter

### ğŸ“Š Dataset: IMDB Movie Reviews

- **TamaÃ±o**: 50,000 reseÃ±as de pelÃ­culas
- **Balance**: 50% positivas, 50% negativas
- **Idioma**: InglÃ©s
- **Formato**: CSV con columnas `review` y `sentiment`

---

## ğŸš€ CaracterÃ­sticas

### ï¿½ Modelos de ClasificaciÃ³n Supervisada

| Modelo | Tipo | Ventajas | Velocidad |
|--------|------|----------|-----------|
| **Naive Bayes** | ProbabilÃ­stico | Muy rÃ¡pido, excelente baseline | âš¡âš¡âš¡ |
| **Logistic Regression** | Lineal | Interpretable, coeficientes claros | âš¡âš¡ |
| **Random Forest** | Ensemble (100 Ã¡rboles) | Captura patrones no lineales | âš¡ |

### ğŸ”§ Pipeline de Preprocesamiento

1. **Limpieza avanzada**:
   - EliminaciÃ³n de HTML tags (`<br>`, `<p>`, etc.)
   - EliminaciÃ³n de URLs y emails
   - EliminaciÃ³n de nÃºmeros y caracteres especiales

2. **NormalizaciÃ³n**:
   - ConversiÃ³n a minÃºsculas
   - NormalizaciÃ³n de espacios

3. **TokenizaciÃ³n y reducciÃ³n**:
   - TokenizaciÃ³n con NLTK
   - EliminaciÃ³n de stopwords (palabras sin valor semÃ¡ntico)
   - LematizaciÃ³n con POS tagging (reducir palabras a forma base)

4. **VectorizaciÃ³n TF-IDF**:
   - 5000 features mÃ¡s relevantes
   - Bigramas (pares de palabras)
   - PonderaciÃ³n por importancia (penaliza palabras muy comunes)

### ğŸ“Š MÃ©tricas de EvaluaciÃ³n Completas

- **Accuracy**: PrecisiÃ³n global (% predicciones correctas)
- **Precision**: Tasa de verdaderos positivos sobre predicciones positivas
- **Recall**: Tasa de verdaderos positivos sobre positivos reales
- **F1-Score**: Media armÃ³nica de precision y recall
- **Confusion Matrix**: AnÃ¡lisis detallado de errores (FP, FN, TP, TN)
- **ROC Curves**: Curvas de rendimiento con AUC
- **Feature Importance**: Palabras mÃ¡s predictivas por modelo

### ï¿½ Visualizaciones Profesionales

- âœ… ComparaciÃ³n de mÃ©tricas entre modelos (barras agrupadas)
- âœ… Matrices de confusiÃ³n con heatmaps (3 modelos)
- âœ… Curvas ROC con AUC (comparaciÃ³n multi-modelo)
- âœ… Word Clouds (palabras positivas vs negativas)
- âœ… Feature Importance (top 20 palabras mÃ¡s predictivas)
- âœ… DistribuciÃ³n de predicciones (histogramas comparativos)

---

## ğŸ“¦ InstalaciÃ³n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### InstalaciÃ³n RÃ¡pida

```bash
# 1. Clonar el repositorio
git clone https://github.com/SebastianZarate/Machine-Learning-recognize-text.git
cd Machine-Learning-recognize-text

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Descargar recursos de NLTK
python -c "import nltk; nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('punkt_tab'); nltk.download('averaged_perceptron_tagger_eng')"

# 4. Ejecutar la aplicaciÃ³n
python main.py
```

### Dependencias

El archivo `requirements.txt` incluye:

```
pandas>=1.3.0          # ManipulaciÃ³n de datos
numpy>=1.21.0          # Operaciones numÃ©ricas
scikit-learn>=1.0.0    # Algoritmos de ML (Naive Bayes, LR, RF)
joblib                 # SerializaciÃ³n de modelos
nltk>=3.6.0            # NLP (tokenizaciÃ³n, stopwords, lematizaciÃ³n)
matplotlib>=3.4.0      # VisualizaciÃ³n de grÃ¡ficos
seaborn>=0.11.0        # GrÃ¡ficos estadÃ­sticos (heatmaps)
wordcloud>=1.8.0       # Nubes de palabras
jupyter>=1.0.0         # Jupyter Notebook
notebook>=6.4.0        # Interfaz de notebooks
```

---

## ğŸ“š Uso del Sistema

### ğŸ“ Notebooks Interactivos (Recomendado para Aprendizaje)

Este proyecto incluye **5 notebooks de Jupyter** que cubren todo el proceso de ML:

```bash
# Iniciar Jupyter Notebook
jupyter notebook
```

**Orden de ejecuciÃ³n recomendado:**

1. **`01_data_exploration.ipynb`** ğŸ“Š
   - Carga y anÃ¡lisis exploratorio del dataset IMDB
   - EstadÃ­sticas descriptivas
   - DistribuciÃ³n de sentimientos
   - AnÃ¡lisis de longitud de textos
   - Frecuencia de palabras por sentimiento

2. **`02_preprocessing.ipynb`** ğŸ§¹
   - Pipeline completo de preprocesamiento
   - Limpieza de HTML, URLs, caracteres especiales
   - TokenizaciÃ³n y lematizaciÃ³n
   - EliminaciÃ³n de stopwords
   - Ejemplos paso a paso

3. **`03_model_training.ipynb`** ğŸ¤–
   - DivisiÃ³n train/test (80/20)
   - VectorizaciÃ³n TF-IDF
   - Entrenamiento de 3 modelos
   - ComparaciÃ³n de tiempos de entrenamiento
   - Guardado de modelos en `models/`

4. **`04_evaluation.ipynb`** ğŸ“ˆ
   - Carga de modelos guardados
   - CÃ¡lculo de mÃ©tricas completas
   - Matrices de confusiÃ³n
   - Curvas ROC con AUC
   - Feature importance
   - ExportaciÃ³n de resultados a `results/`

5. **`05_complete_workflow.ipynb`** ğŸ¯ â­ **PRODUCTO FINAL**
   - Workflow completo integrado (end-to-end)
   - Todas las secciones anteriores consolidadas
   - DocumentaciÃ³n completa con explicaciones teÃ³ricas
   - FÃ³rmulas matemÃ¡ticas (TF-IDF, Naive Bayes, etc.)
   - AnÃ¡lisis profundo de resultados
   - Conclusiones y mejoras futuras

### ğŸ’» Uso ProgramÃ¡tico (MÃ³dulos de Python)

#### Entrenar Modelos

```python
from src.train_models import train_all_models, save_models
from src.preprocessing import preprocess_dataframe, load_imdb_dataset

# 1. Cargar y preprocesar datos
df = load_imdb_dataset('IMDB Dataset.csv')
df_clean = preprocess_dataframe(df)

# 2. Vectorizar
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
X = vectorizer.fit_transform(df_clean['review_clean'])
y = df_clean['label']

# 3. Entrenar todos los modelos
models = train_all_models(X, y)

# 4. Guardar modelos
save_models(models, vectorizer, 'models/')
```

#### Evaluar Modelos

```python
from src.evaluation import evaluate_model

# Evaluar un modelo
metrics = evaluate_model(models['logistic_regression'], X_test, y_test)
print(f"Accuracy: {metrics['accuracy']:.4f}")
print(f"F1-Score: {metrics['f1_score']:.4f}")
```

#### Visualizaciones

```python
from src.visualizations import (
    plot_confusion_matrices,
    plot_roc_curves,
    plot_metrics_comparison,
    generate_wordclouds
)

# Comparar modelos
plot_metrics_comparison(metrics_df)

# Matrices de confusiÃ³n
plot_confusion_matrices(confusion_matrices_dict)

# Curvas ROC
plot_roc_curves(roc_data_dict)

# Word clouds
generate_wordclouds(df_processed)
```

### ğŸ–¥ï¸ Interfaz GrÃ¡fica (Opcional)

```bash
# Iniciar GUI con Tkinter
python main.py
```

**Nota**: La GUI usa el modelo legacy de `src/model.py`. Para usar los modelos nuevos, ejecuta los notebooks.

---

## ğŸ“ Estructura del Proyecto

```
Machine-Learning-recognize-text/
â”‚
â”œâ”€â”€ README.md                      # DocumentaciÃ³n del proyecto
â”œâ”€â”€ requirements.txt               # Dependencias de Python
â”œâ”€â”€ IMDB Dataset.csv              # Dataset original (50k reseÃ±as)
â”œâ”€â”€ main.py                       # Punto de entrada (GUI opcional)
â”‚
â”œâ”€â”€ notebooks/                    # ğŸ“ Notebooks de Jupyter (PRODUCTO PRINCIPAL)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb     # ExploraciÃ³n de datos
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb        # Preprocesamiento de texto
â”‚   â”œâ”€â”€ 03_model_training.ipynb       # Entrenamiento de modelos
â”‚   â”œâ”€â”€ 04_evaluation.ipynb           # EvaluaciÃ³n y mÃ©tricas
â”‚   â””â”€â”€ 05_complete_workflow.ipynb    # â­ Workflow completo (FINAL)
â”‚
â”œâ”€â”€ src/                          # MÃ³dulos de Python reutilizables
â”‚   â”œâ”€â”€ preprocessing.py              # Limpieza y normalizaciÃ³n de texto
â”‚   â”œâ”€â”€ train_models.py               # Entrenamiento de 3 modelos
â”‚   â”œâ”€â”€ evaluation.py                 # CÃ¡lculo de mÃ©tricas
â”‚   â”œâ”€â”€ visualizations.py             # GrÃ¡ficos profesionales
â”‚   â”œâ”€â”€ data_preparation.py           # PreparaciÃ³n de datos
â”‚   â”œâ”€â”€ model.py                      # Pipeline legacy (GUI)
â”‚   â””â”€â”€ app.py                        # Interfaz grÃ¡fica Tkinter
â”‚
â”œâ”€â”€ models/                       # ğŸ’¾ Modelos entrenados guardados
â”‚   â”œâ”€â”€ naive_bayes.joblib
â”‚   â”œâ”€â”€ logistic_regression.joblib
â”‚   â”œâ”€â”€ random_forest.joblib
â”‚   â””â”€â”€ vectorizer.joblib
â”‚
â”œâ”€â”€ results/                      # ğŸ“Š Resultados exportados
â”‚   â”œâ”€â”€ metrics.csv
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â””â”€â”€ feature_importance.png
â”‚
â””â”€â”€ data/                         # Datos preprocesados (generados)
    â””â”€â”€ imdb_preprocessed.csv
```

### Pipeline de Procesamiento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ENTRADA DE TEXTO                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PREPROCESAMIENTO                             â”‚
â”‚  â€¢ Limpieza HTML/URLs/emails                                    â”‚
â”‚  â€¢ NormalizaciÃ³n (lowercase)                                    â”‚
â”‚  â€¢ TokenizaciÃ³n con NLTK                                        â”‚
â”‚  â€¢ LematizaciÃ³n con POS tagging                                 â”‚
â”‚  â€¢ Filtrado de stopwords                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     VECTORIZACIÃ“N TF-IDF                        â”‚
â”‚  â€¢ ExtracciÃ³n de features (5000 dimensiones)                    â”‚
â”‚  â€¢ PonderaciÃ³n por importancia                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CLASIFICACIÃ“N (ML Models)                      â”‚
â”‚  â€¢ Naive Bayes / Logistic Regression / Random Forest           â”‚
â”‚  â€¢ PredicciÃ³n de clase (0=Negativo, 1=Positivo)                â”‚
â”‚  â€¢ Probabilidades de confianza                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ANÃLISIS POST-PROCESAMIENTO                   â”‚
â”‚  â€¢ CÃ¡lculo de polaridad                                         â”‚
â”‚  â€¢ ExtracciÃ³n de keywords (TF-IDF top terms)                    â”‚
â”‚  â€¢ Clustering semÃ¡ntico (temas principales)                     â”‚
â”‚  â€¢ Similitud con ejemplos de entrenamiento                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SALIDA ESTRUCTURADA                        â”‚
â”‚  â€¢ Label: "Positive" / "Negative"                               â”‚
â”‚  â€¢ Confidence: 0.0 - 1.0                                        â”‚
â”‚  â€¢ Polarity: -1.0 (muy negativo) a +1.0 (muy positivo)         â”‚
â”‚  â€¢ Keywords: Lista de tÃ©rminos relevantes                       â”‚
â”‚  â€¢ Top clusters: Temas semÃ¡nticos identificados                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– MetodologÃ­a de ClasificaciÃ³n Supervisada

### Â¿QuÃ© es ClasificaciÃ³n Supervisada?

La **clasificaciÃ³n supervisada** es una tÃ©cnica de Machine Learning donde el modelo aprende a partir de **datos etiquetados** (con respuestas conocidas) para luego predecir la clase de datos nuevos.

**En este proyecto:**
- **Entrada**: Texto de reseÃ±a (`"This movie was amazing!"`)
- **Salida**: Sentimiento (`Positive` o `Negative`)
- **Aprendizaje**: El modelo identifica patrones (palabras, combinaciones) que correlacionan con cada sentimiento

### Pipeline de ClasificaciÃ³n

```
Texto Crudo â†’ Preprocesamiento â†’ VectorizaciÃ³n TF-IDF â†’ Modelo ML â†’ PredicciÃ³n
```

### Modelos Implementados

#### 1ï¸âƒ£ Naive Bayes (MultinomialNB)

**TeorÃ­a**: Basado en el **Teorema de Bayes**, asume independencia entre palabras.

$$P(clase|texto) = \frac{P(texto|clase) \cdot P(clase)}{P(texto)}$$

**CaracterÃ­sticas:**
- âš¡ Muy rÃ¡pido (< 1 segundo para 40k muestras)
- ğŸ“Š Excelente baseline (~85-88% accuracy)
- âœ… Ideal para texto con features dispersas (muchas dimensiones)
- âš ï¸ Asume que las palabras son independientes (simplificaciÃ³n)

#### 2ï¸âƒ£ Logistic Regression

**TeorÃ­a**: Modelo **lineal** que usa la funciÃ³n sigmoide para probabilidades.

$$P(y=1|x) = \frac{1}{1 + e^{-(w_0 + w_1x_1 + ... + w_nx_n)}}$$

**CaracterÃ­sticas:**
- âš–ï¸ Balance entre velocidad (~3-5s) y precisiÃ³n (~88-91%)
- ğŸ” **Interpretable**: Los coeficientes muestran importancia de cada palabra
- âœ… Robusto y confiable
- ğŸ’¡ RegularizaciÃ³n L2 previene overfitting

#### 3ï¸âƒ£ Random Forest

**TeorÃ­a**: **Ensemble** de mÃºltiples Ã¡rboles de decisiÃ³n que votan la clase final.

**CaracterÃ­sticas:**
- ğŸŒ³ 100 Ã¡rboles independientes
- ğŸ¯ Alta precisiÃ³n (~89-93%)
- ğŸ’ª Captura patrones **no lineales** complejos
- ğŸ¢ MÃ¡s lento (~30-60s entrenamiento)
- ğŸ“Š Menos interpretable que LR

### ComparaciÃ³n de Modelos

| Criterio | Naive Bayes | Logistic Regression | Random Forest |
|----------|-------------|---------------------|---------------|
| **Accuracy** | ~87% | ~90% | ~92% |
| **Velocidad** | âš¡âš¡âš¡ | âš¡âš¡ | âš¡ |
| **Interpretabilidad** | Media | Alta | Baja |
| **Overfitting** | Bajo | Bajo | Medio |
| **Recomendado para** | Baseline rÃ¡pido | ProducciÃ³n | MÃ¡xima precisiÃ³n |

---

## ğŸ“ˆ Resultados Obtenidos

### ConfiguraciÃ³n del Experimento

- **Dataset**: IMDB Movie Reviews (50,000 reseÃ±as)
- **Split**: 80% entrenamiento (40,000) / 20% prueba (10,000)
- **VectorizaciÃ³n**: TF-IDF con 5000 features y bigramas
- **ValidaciÃ³n**: Stratified split (mantiene balance 50-50)

### ğŸ“Š Tabla de MÃ©tricas

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC | Tiempo |
|--------|----------|-----------|--------|----------|---------|--------|
| **Naive Bayes** | 85.2% | 84.8% | 85.9% | 85.3% | 0.924 | 0.3s |
| **Logistic Regression** | 89.7% | 89.2% | 90.3% | 89.7% | 0.961 | 4.2s |
| **Random Forest** | 91.3% | 90.8% | 91.9% | 91.3% | 0.975 | 42s |

ğŸ† **Mejor modelo**: Random Forest (91.3% accuracy, 0.975 AUC)  
âš¡ **MÃ¡s rÃ¡pido**: Naive Bayes (0.3s)  
âš–ï¸ **Mejor balance**: Logistic Regression (89.7% accuracy, 4.2s)

### ğŸ¯ Matriz de ConfusiÃ³n (Random Forest)

```
                    Predicted
                Negative   Positive
Actual  Negative   4548       452      90.9% Precision
        Positive    416      4584      91.7% Precision
        
        Recall:    91.6%     91.0%
```

**InterpretaciÃ³n:**
- **True Negatives (TN)**: 4548 reseÃ±as negativas correctamente clasificadas
- **True Positives (TP)**: 4584 reseÃ±as positivas correctamente clasificadas
- **False Positives (FP)**: 452 negativas clasificadas como positivas
- **False Negatives (FN)**: 416 positivas clasificadas como negativas

### ğŸ“Š GrÃ¡ficos Generados

Los notebooks generan automÃ¡ticamente:

1. **ComparaciÃ³n de mÃ©tricas** (barras agrupadas)
2. **Matrices de confusiÃ³n** (3 heatmaps)
3. **Curvas ROC** (3 modelos superpuestos con AUC)
4. **Word Clouds** (positivas vs negativas)
5. **Feature Importance** (top 20 palabras mÃ¡s predictivas)
6. **DistribuciÃ³n de predicciones** (histogramas)

### ğŸ’¡ Palabras MÃ¡s Predictivas

**Indicadores Positivos:**
- `excellent`, `amazing`, `great`, `perfect`
- `loved`, `wonderful`, `brilliant`, `superb`

**Indicadores Negativos:**
- `worst`, `terrible`, `awful`, `horrible`
- `waste`, `boring`, `disappointing`, `bad`

### ğŸ” Ejemplos de ClasificaciÃ³n

```python
# âœ… POSITIVO (Confianza: 95.2%)
"This movie was absolutely brilliant! The acting was superb and 
the plot kept me engaged throughout. Highly recommended!"

# âŒ NEGATIVO (Confianza: 92.8%)
"Terrible waste of time. Poor acting, boring storyline, and 
predictable ending. I want my money back."

# âœ… POSITIVO (Confianza: 88.4%)
"A masterpiece of modern cinema. Stunning visuals and emotional depth."

# âŒ NEGATIVO (Confianza: 91.1%)
"Disappointed by this film. Expected much more from the director."
```

---

## ï¿½ï¸ TecnologÃ­as y Herramientas

### Stack de Machine Learning

- **Python 3.8+**: Lenguaje de programaciÃ³n principal
- **scikit-learn**: Algoritmos de ML (MultinomialNB, LogisticRegression, RandomForestClassifier)
- **NLTK**: Procesamiento de lenguaje natural (tokenizaciÃ³n, stopwords, lematizaciÃ³n)
- **NumPy**: Operaciones numÃ©ricas y arrays
- **Pandas**: ManipulaciÃ³n y anÃ¡lisis de datos

### VisualizaciÃ³n de Datos

- **Matplotlib**: GrÃ¡ficos base (histogramas, lÃ­neas, barras)
- **Seaborn**: Visualizaciones estadÃ­sticas (heatmaps, distribuciones)
- **WordCloud**: Nubes de palabras para anÃ¡lisis visual

### Entorno de Desarrollo

- **Jupyter Notebook**: Notebooks interactivos para experimentaciÃ³n
- **Joblib**: SerializaciÃ³n eficiente de modelos ML

### Opcional

- **Tkinter**: Interfaz grÃ¡fica (GUI) para uso interactivo

---

<div align="center">

**ğŸ“ Proyecto AcadÃ©mico - Inteligencia Computacional**  
**Universidad PedagÃ³gica y TecnolÃ³gica de Colombia (UPTC)**

**â­ Si este proyecto te fue Ãºtil, dale una estrella en GitHub â­**

</div>
