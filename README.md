# ğŸ¬ Machine Learning Text Classification

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![NLTK](https://img.shields.io/badge/NLTK-3.8+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**Sistema avanzado de clasificaciÃ³n de texto usando Machine Learning para anÃ¡lisis de sentimientos en reseÃ±as de pelÃ­culas**

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢ [InstalaciÃ³n](#-instalaciÃ³n) â€¢ [Uso](#-uso) â€¢ [Arquitectura](#-arquitectura) â€¢ [Modelos](#-modelos)

</div>

---

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un **sistema completo de clasificaciÃ³n de texto** utilizando tÃ©cnicas avanzadas de Machine Learning y Procesamiento de Lenguaje Natural (NLP). El sistema puede:

- âœ… **Entrenar** mÃºltiples modelos de clasificaciÃ³n (Naive Bayes, Logistic Regression, Random Forest)
- âœ… **Clasificar** textos en tiempo real (positivo/negativo)
- âœ… **Analizar** sentimientos con mÃ©tricas de confianza
- âœ… **Visualizar** resultados con grÃ¡ficos interactivos
- âœ… **Comparar** rendimiento de diferentes algoritmos

### ğŸ¯ Casos de Uso

- AnÃ¡lisis de sentimientos en reseÃ±as de productos
- ClasificaciÃ³n de opiniones de usuarios
- Monitoreo de marca en redes sociales
- AnÃ¡lisis de feedback de clientes
- InvestigaciÃ³n en procesamiento de lenguaje natural

---

## ğŸš€ CaracterÃ­sticas

### ğŸ§  Modelos de Machine Learning

| Modelo | CaracterÃ­sticas | Ventajas |
|--------|----------------|----------|
| **Naive Bayes** | ProbabilÃ­stico, rÃ¡pido | Excelente para baseline, muy veloz |
| **Logistic Regression** | Linear, interpretable | Balance entre velocidad y precisiÃ³n |
| **Random Forest** | Ensemble, robusto | Captura patrones complejos no lineales |

### ğŸ”§ Procesamiento Avanzado de Texto

- **Limpieza de datos**: EliminaciÃ³n de HTML, URLs, emails, menciones
- **TokenizaciÃ³n**: SegmentaciÃ³n inteligente con NLTK
- **LematizaciÃ³n**: ReducciÃ³n a raÃ­z con anÃ¡lisis morfolÃ³gico (POS tagging)
- **Stopwords**: Filtrado de palabras irrelevantes
- **TF-IDF**: VectorizaciÃ³n con ponderaciÃ³n de importancia
- **Clustering**: AgrupaciÃ³n semÃ¡ntica con K-Means

### ğŸ“Š MÃ©tricas y EvaluaciÃ³n

- **Accuracy**: PrecisiÃ³n global del modelo
- **Precision/Recall/F1-Score**: MÃ©tricas detalladas por clase
- **Confusion Matrix**: AnÃ¡lisis de errores (FP, FN, TP, TN)
- **ROC-AUC**: Curvas de rendimiento
- **Word Clouds**: VisualizaciÃ³n de tÃ©rminos mÃ¡s frecuentes
- **Feature Importance**: AnÃ¡lisis de caracterÃ­sticas relevantes

### ğŸ–¥ï¸ Interfaz GrÃ¡fica (GUI)

- **Entrenamiento visual**: Carga de datasets desde CSV
- **ClasificaciÃ³n en tiempo real**: PredicciÃ³n instantÃ¡nea
- **Dashboard de mÃ©tricas**: Confianza, polaridad, keywords
- **AnÃ¡lisis semÃ¡ntico**: IdentificaciÃ³n de temas principales
- **ExportaciÃ³n de resultados**: Guardado de predicciones

---

## ğŸ“¦ InstalaciÃ³n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### InstalaciÃ³n RÃ¡pida

```bash
# 1. Clonar el repositorio
git clone https://github.com/SebastianZarate/Machine-Learning-recognize-text.git
cd Machine-Learning-recognize-text

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar la aplicaciÃ³n
python main.py
```

### Dependencias

El archivo `requirements.txt` incluye:

```
pandas>=1.3.0          # ManipulaciÃ³n de datos
numpy>=1.20.0          # Operaciones numÃ©ricas
scikit-learn>=1.0.0    # Algoritmos de ML
joblib                 # SerializaciÃ³n de modelos
nltk>=3.8.0            # Procesamiento de lenguaje natural
matplotlib>=3.5.0      # VisualizaciÃ³n de grÃ¡ficos
seaborn>=0.12.0        # GrÃ¡ficos estadÃ­sticos
wordcloud>=1.8.2       # Nubes de palabras
```

---

## ğŸ® Uso

### 1ï¸âƒ£ Interfaz GrÃ¡fica (Recomendado)

```bash
python main.py
```

La GUI permite:

1. **Entrenar modelo**: Cargar dataset CSV con reseÃ±as
2. **Clasificar texto**: Escribir o pegar texto para analizar
3. **Ver resultados**: MÃ©tricas de confianza, polaridad y keywords

### 2ï¸âƒ£ Uso ProgramÃ¡tico

#### Entrenar un Modelo

```python
from src.model import train_from_csv

# Entrenar modelo desde archivo CSV
train_from_csv(
    csv_path="IMDB Dataset.csv",
    model_path="models/review_model.joblib"
)
```

#### Clasificar Texto

```python
from src.model import predict_text

# Clasificar una reseÃ±a
text = "This movie was absolutely amazing! Great acting and plot."
result = predict_text(text, model_path="models/review_model.joblib")

print(f"Sentimiento: {result['label']}")  # 'Positive' o 'Negative'
print(f"Confianza: {result['confidence']:.2%}")
print(f"Polaridad: {result['polarity']:.2f}")
print(f"Keywords: {', '.join(result['keywords'][:5])}")
```

#### Entrenar y Evaluar MÃºltiples Modelos

```python
from src.train_models import train_all_models, evaluate_all_models
from sklearn.feature_extraction.text import TfidfVectorizer

# Vectorizar textos
vectorizer = TfidfVectorizer(max_features=5000)
X_train = vectorizer.fit_transform(train_texts)

# Entrenar todos los modelos
models = train_all_models(X_train, y_train)

# Evaluar modelos
X_test = vectorizer.transform(test_texts)
results = evaluate_all_models(models, X_test, y_test)

# Mostrar resultados
for model_name, metrics in results.items():
    print(f"{model_name}: {metrics['accuracy']:.4f}")
```

### 3ï¸âƒ£ Crear Dataset Balanceado

```python
from src.data_preparation import create_balanced_dataset

# Crear dataset con positivos (reseÃ±as) y negativos (textos sintÃ©ticos)
create_balanced_dataset(
    imdb_path="IMDB Dataset.csv",
    output_path="balanced_dataset.csv",
    positive_count=40000,
    negative_count=40000
)
```

### 4ï¸âƒ£ Visualizaciones

```python
from src.visualizations import (
    plot_model_comparison_bars,
    plot_confusion_matrices,
    plot_roc_curves_comparison,
    plot_word_cloud
)

# Comparar rendimiento de modelos
fig = plot_model_comparison_bars(eval_results)
fig.savefig("model_comparison.png")

# Graficar matrices de confusiÃ³n
fig = plot_confusion_matrices(eval_results)
fig.savefig("confusion_matrices.png")

# Curvas ROC
fig = plot_roc_curves_comparison(models, X_test, y_test)
fig.savefig("roc_curves.png")

# Word cloud de textos positivos
fig = plot_word_cloud(positive_texts, title="Palabras Positivas")
fig.savefig("positive_wordcloud.png")
```

---

## ğŸ—ï¸ Arquitectura

### Estructura del Proyecto

```
Machine-Learning-recognize-text/
â”‚
â”œâ”€â”€ main.py                    # Punto de entrada de la aplicaciÃ³n
â”œâ”€â”€ requirements.txt           # Dependencias del proyecto
â”œâ”€â”€ IMDB Dataset.csv          # Dataset de entrenamiento (opcional)
â”‚
â”œâ”€â”€ models/                   # Modelos entrenados guardados
â”‚   â””â”€â”€ review_model.joblib   # Modelo serializado con joblib
â”‚
â””â”€â”€ src/                      # CÃ³digo fuente modular
    â”œâ”€â”€ app.py                # Interfaz grÃ¡fica con Tkinter
    â”œâ”€â”€ model.py              # Pipeline completo de ML (nÃºcleo)
    â”œâ”€â”€ train_models.py       # Entrenamiento de modelos supervisados
    â”œâ”€â”€ evaluation.py         # EvaluaciÃ³n y mÃ©tricas
    â”œâ”€â”€ data_preparation.py   # PreparaciÃ³n y balanceo de datos
    â””â”€â”€ visualizations.py     # GrÃ¡ficos y visualizaciones
```

### Pipeline de Procesamiento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ENTRADA DE TEXTO                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PREPROCESAMIENTO                             â”‚
â”‚  â€¢ Limpieza HTML/URLs/emails                                    â”‚
â”‚  â€¢ NormalizaciÃ³n (lowercase)                                    â”‚
â”‚  â€¢ TokenizaciÃ³n con NLTK                                        â”‚
â”‚  â€¢ LematizaciÃ³n con POS tagging                                 â”‚
â”‚  â€¢ Filtrado de stopwords                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     VECTORIZACIÃ“N TF-IDF                        â”‚
â”‚  â€¢ ExtracciÃ³n de features (5000 dimensiones)                    â”‚
â”‚  â€¢ PonderaciÃ³n por importancia                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CLASIFICACIÃ“N (ML Models)                      â”‚
â”‚  â€¢ Naive Bayes / Logistic Regression / Random Forest           â”‚
â”‚  â€¢ PredicciÃ³n de clase (0=Negativo, 1=Positivo)                â”‚
â”‚  â€¢ Probabilidades de confianza                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ANÃLISIS POST-PROCESAMIENTO                   â”‚
â”‚  â€¢ CÃ¡lculo de polaridad                                         â”‚
â”‚  â€¢ ExtracciÃ³n de keywords (TF-IDF top terms)                    â”‚
â”‚  â€¢ Clustering semÃ¡ntico (temas principales)                     â”‚
â”‚  â€¢ Similitud con ejemplos de entrenamiento                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SALIDA ESTRUCTURADA                        â”‚
â”‚  â€¢ Label: "Positive" / "Negative"                               â”‚
â”‚  â€¢ Confidence: 0.0 - 1.0                                        â”‚
â”‚  â€¢ Polarity: -1.0 (muy negativo) a +1.0 (muy positivo)         â”‚
â”‚  â€¢ Keywords: Lista de tÃ©rminos relevantes                       â”‚
â”‚  â€¢ Top clusters: Temas semÃ¡nticos identificados                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– Modelos

### 1. Naive Bayes (Baseline)

**Teorema de Bayes aplicado a clasificaciÃ³n de texto:**

$$P(clase|documento) = \frac{P(documento|clase) \cdot P(clase)}{P(documento)}$$

- âš¡ **Velocidad**: ~0.1-0.5 segundos para 80k muestras
- ğŸ“Š **PrecisiÃ³n tÃ­pica**: 85-88%
- âœ… **Ventajas**: Muy rÃ¡pido, funciona bien con features dispersas
- âŒ **Limitaciones**: Asume independencia entre palabras

### 2. Logistic Regression (Linear)

**Modelo lineal con funciÃ³n logÃ­stica:**

$$P(y=1|x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + ... + \beta_n x_n)}}$$

- âš¡ **Velocidad**: ~2-5 segundos para 80k muestras
- ğŸ“Š **PrecisiÃ³n tÃ­pica**: 88-91%
- âœ… **Ventajas**: Interpretable, balanceado, coeficientes interpretables
- âŒ **Limitaciones**: Solo relaciones lineales

### 3. Random Forest (Ensemble)

**Ensemble de mÃºltiples Ã¡rboles de decisiÃ³n:**

- ğŸŒ³ **100 Ã¡rboles** con profundidad mÃ¡xima de 20
- âš¡ **Velocidad**: ~30-60 segundos para 80k muestras
- ğŸ“Š **PrecisiÃ³n tÃ­pica**: 89-93%
- âœ… **Ventajas**: Captura patrones complejos, robusto a outliers
- âŒ **Limitaciones**: MÃ¡s lento, menos interpretable

### ComparaciÃ³n de Rendimiento

| MÃ©trica | Naive Bayes | Logistic Regression | Random Forest |
|---------|-------------|---------------------|---------------|
| **Accuracy** | ~87% | ~90% | ~92% |
| **Precision** | ~86% | ~89% | ~91% |
| **Recall** | ~88% | ~91% | ~93% |
| **F1-Score** | ~87% | ~90% | ~92% |
| **Tiempo entrenamiento** | 0.2s | 3s | 45s |
| **Tiempo predicciÃ³n** | 0.01s | 0.02s | 0.1s |

---

## ğŸ“ˆ Resultados

### Dataset IMDB

- **TamaÃ±o**: 50,000 reseÃ±as de pelÃ­culas
- **Balance**: 50% positivas, 50% negativas
- **Split**: 80% entrenamiento, 20% prueba

### MÃ©tricas de EvaluaciÃ³n

```
=== RANDOM FOREST (Mejor Modelo) ===
Accuracy:    92.3%
Precision:   91.8%
Recall:      93.1%
F1-Score:    92.4%
ROC-AUC:     0.978

Confusion Matrix:
                Predicted
                Neg    Pos
Actual  Neg   [4520   480]
        Pos   [ 290  4710]
```

### Ejemplos de ClasificaciÃ³n

```python
# âœ… Positivo (Confianza: 96.4%)
"This movie was absolutely brilliant! The acting was superb and 
the plot kept me engaged throughout. Highly recommended!"

# âŒ Negativo (Confianza: 91.2%)
"Terrible waste of time. Poor acting, boring storyline, and 
predictable ending. I want my money back."

# âœ… Positivo (Confianza: 87.3%)
"A masterpiece of modern cinema. Stunning visuals and emotional depth."
```

---

## ğŸ”¬ TecnologÃ­as Utilizadas

### Core

- **Python 3.8+**: Lenguaje principal
- **scikit-learn**: Algoritmos de ML
- **NLTK**: Procesamiento de lenguaje natural
- **NumPy**: Operaciones numÃ©ricas
- **Pandas**: ManipulaciÃ³n de datos

### VisualizaciÃ³n

- **Matplotlib**: GrÃ¡ficos base
- **Seaborn**: Visualizaciones estadÃ­sticas
- **WordCloud**: Nubes de palabras

### GUI

- **Tkinter**: Interfaz grÃ¡fica nativa

### Persistencia

- **Joblib**: SerializaciÃ³n eficiente de modelos

---

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### Ajuste de HiperparÃ¡metros

Editar `src/train_models.py`:

```python
# Naive Bayes
MultinomialNB(alpha=1.0)  # Suavizado de Laplace (default: 1.0)

# Logistic Regression
LogisticRegression(
    C=1.0,              # RegularizaciÃ³n (menor = mÃ¡s regularizaciÃ³n)
    max_iter=1000,      # Iteraciones mÃ¡ximas
    solver='lbfgs'      # Algoritmo de optimizaciÃ³n
)

# Random Forest
RandomForestClassifier(
    n_estimators=100,   # NÃºmero de Ã¡rboles (mayor = mejor pero mÃ¡s lento)
    max_depth=20,       # Profundidad mÃ¡xima (evita overfitting)
    n_jobs=-1           # Usar todos los cores de CPU
)
```

### Personalizar Preprocesamiento

Editar `src/model.py`:

```python
# TF-IDF Vectorizer
TfidfVectorizer(
    max_features=5000,      # Dimensiones de features
    min_df=2,               # MÃ­nimo de documentos por tÃ©rmino
    max_df=0.8,             # MÃ¡ximo de documentos por tÃ©rmino
    ngram_range=(1, 2)      # Unigramas y bigramas
)
```

---

## ğŸ“š DocumentaciÃ³n Adicional

### MÃ³dulos Principales

#### `model.py` - Pipeline Completo

Funciones clave:
- `preprocess_text()`: Limpieza y normalizaciÃ³n
- `train_from_csv()`: Entrenamiento desde CSV
- `predict_text()`: ClasificaciÃ³n de texto
- `analyze_keywords()`: ExtracciÃ³n de tÃ©rminos clave
- `identify_clusters()`: AgrupaciÃ³n semÃ¡ntica

#### `train_models.py` - Entrenamiento

Funciones clave:
- `train_all_models()`: Entrenar Naive Bayes, Logistic Regression, Random Forest
- `evaluate_model()`: Calcular mÃ©tricas de un modelo
- `evaluate_all_models()`: Comparar mÃºltiples modelos
- `save_models()`: Guardar modelos entrenados

#### `evaluation.py` - EvaluaciÃ³n

Funciones clave:
- `evaluate_model()`: MÃ©tricas completas (accuracy, precision, recall, F1, ROC-AUC)
- `print_classification_report()`: Reporte detallado por clase
- `calculate_specificity()`: True Negative Rate

#### `visualizations.py` - GrÃ¡ficos

Funciones clave:
- `plot_model_comparison_bars()`: ComparaciÃ³n de modelos
- `plot_confusion_matrices()`: Matrices de confusiÃ³n
- `plot_roc_curves_comparison()`: Curvas ROC
- `plot_word_cloud()`: Nubes de palabras
- `plot_feature_importance()`: Importancia de features

---

<div align="center">

**â­ Si te ha gustado este proyecto, dale una estrella en GitHub â­**

</div>
